{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 - Basics of ML\n",
    "Include your code in the relevant cells below.\n",
    "Subparts labeled as questions (Q1.1, Q1.2, etc.) should have their answers filled in or plots placed prominently, as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important note: \n",
    "\n",
    "On this and future homeworks, depending on the data size and your hardware configuration, experiments may take too long if you use the complete dataset. This would be counter-productive, as you will need to run multiple experiments. Accordingly, please start first with a smaller sample that will allow you to run your code in a reasonable time.\n",
    "\n",
    "Once you complete all tasks, before the final submission, you can allow longer run times and run your code with the complete set. However, if this is still taking too much time or causing your computer to freeze it will be OK to submit experiments using a sample size that is feasible for your setting.\n",
    "\n",
    "Grading of the homework will not be affected from this type of variations in the design of your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1: Understanding the data\n",
    "- Load MNIST Fashion training and testing datasets with reduced size (n6000 for training and n1000 for testing)\n",
    "https://drive.google.com/drive/folders/1ytbYCba9LUU_8L2V8Bks7pIfu4x1sXQy\n",
    "\n",
    "Q1.1: What is the number of features in this dataset:   ___\n",
    "\n",
    "Q1.2: What is the number of samples in this dataset:   ___\n",
    "\n",
    "Q1.3: What is the dimensionality of each data sample: ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2: Viewing the data\n",
    "- Select one random example from each category from the training set. Convert the feature vector for the selected example to a 2D image. Display the image with the name of the category\n",
    "\n",
    "Q2.1: Show the example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3: Exploring the dataset\n",
    "- Select all images in category \"Dress\" in the training set. Create and display a pixel-wise \"average image\" for this category.\n",
    "- Create and display a pixel-wise \"standard deviation image\" for this category.\n",
    "- Repeat the items above for the the category \"Dress\" in the testing set. Compare the average and standard deviation images.\n",
    "- Repeat the items above for a different category you select.\n",
    "\n",
    "Q3.1: Plot the 2D mean and std images for dresses in training and testing sets\n",
    "\n",
    "Q3.2: Plot the 2D mean and std images for the category you selected in training and testing sets\n",
    "\n",
    "Q3.3: Comment on differences between the mean and std images from training and testing datasets. What do you notice, and what might it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4: Image distances\n",
    "- In the training set, find the dress image that is most dissimilar to the average dress image. Show it as a 2D image\n",
    "- In the training set, find the dress image most similar to mean image. Show it as a 2D image\n",
    "\n",
    "Hint: You can use the \"euclidian distance\" as your similarity metric. Given that an image i in category dress is represented with a flattened feature vector v_i , and the mean image for category dress with the feature vector v_m, the distance between these two images can be calculated using the vector norm of their differences ( | v_i - v_m | ) \n",
    "\n",
    "Q4.1: What is the index of most dissimilar dress image:   ___\n",
    "\n",
    "Q4.2: What is the index of most average looking dress image:   ___\n",
    "\n",
    "Q4.3: Plot the most dissimilar dress image in 2D:   ___\n",
    "\n",
    "Q4.4: Plot the most similar dress image in 2D:   ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5: Image distances, part 2\n",
    "- Repeat questions S3 and S4 after binarizing the images first\n",
    "\n",
    "Q5.1: What is the index of most dissimilar dress image:   ___\n",
    "\n",
    "Q5.2: What is the index of most similar dress image:   ___\n",
    "\n",
    "Q5.3: Did the answer change after binarization? How do you interprete this finding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6: Binary classification between dresses and sandals\n",
    "- Select images from these two categories (dresses and sandals) in the training dataset\n",
    "- Split them into two sets (Set1, Set2) with 70% to 30% random split\n",
    "- Replace category labels as 0 (dress) and 1 (sandal)\n",
    "- Use Set1 to train a linear SVM classifier with default parameters and predict the class labels for Set2 \n",
    "- Use Set2 to train a linear SVM classifier with default parameters and predict the class labels for Set1 \n",
    "\n",
    "Q6.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q6.2: What is the prediction accuracy using the model trained on Set2:   ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7: Binary classification between dresses and sandals, part 2\n",
    "- Select images from these two categories (dresses and sandals) in the training dataset\n",
    "- Split them into two sets (Set1, Set2) with 20% to 80% random split\n",
    "- Select images from these two categories in the testing dataset\n",
    "- Replace category labels as 0 (dress) and 1 (sandal)\n",
    "- Use Set1 to train a linear SVM classifier with default parameters and predict the class labels for testing images \n",
    "- Use Set2 to train a linear SVM classifier with default parameters and predict the class labels for testing images\n",
    "\n",
    "Q7.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q7.2: What is the prediction accuracy using the model trained on Set2:   ___\n",
    "\n",
    "Q7.3: Comment on the differences in the accuracy of the two models. If there is a difference, why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S8: k-NN Error Analysis\n",
    "- In training and testing datasets select the images with labels: Dress, Coat, Sandal, Shirt or Sneaker\n",
    "- Train a k-NN classifier using 4 to 40 nearest neighbors with a step size of 4\n",
    "- Calculate and plot overall testing accuracy for each experiment\n",
    "\n",
    "Q8.1: For k=4 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q8.2: For k=20 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q8.3: What is the label pair that was confused most often (i.e. class A is labeled as B, and vice versa):   ___\n",
    "\n",
    "Q8.4: Visualize 5 mislabeled samples with their actual and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9: Feature extraction\n",
    "- We describe each image by using a reduced set of features (compared to n=784 initial features for each pixel value) as follows:\n",
    "  \n",
    "  1. Binarize the image (background=0, foreground=1)\n",
    "  2. For each row i, find m_i, the index of the first non-zero pixel (m_i will be a value from 0 to 28 - if all pixels in a row are zero then m_i=28)\n",
    "  \n",
    "  Example image:\n",
    "       0 0 0 0 1 1 1 ...\n",
    "       0 0 1 1 1 0 0 ...\n",
    "       0 0 0 0 0 1 0 ...\n",
    "       ...\n",
    "  Extracted features:     [4, 2, 5, ...]\n",
    "  \n",
    "  This strategy gives a feature vector with n=28 features (for each row)\n",
    "  \n",
    "  Repeat classification experiments in Q6 using this reduced feature set.\n",
    "\n",
    "Q9.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q9.2: What is the prediction accuracy using the model trained on Set2:   ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Repeat S9 by extracting 28x4 features this time by applying the same rule in four different directions and concatenating them (left->right, right->left, top->bottom, bottom->top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
