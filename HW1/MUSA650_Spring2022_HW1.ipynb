{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 - Basics of ML\n",
    "Include your code in the relevant cells below.\n",
    "Subparts labeled as questions (Q1.1, Q1.2, etc.) should have their answers filled in or plots placed prominently, as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important note: \n",
    "\n",
    "On this and future homeworks, depending on the data size and your hardware configuration, experiments may take too long if you use the complete dataset. This would be counter-productive, as you will need to run multiple experiments. Accordingly, please start first with a smaller sample that will allow you to run your code in a reasonable time.\n",
    "\n",
    "Once you complete all tasks, before the final submission, you can allow longer run times and run your code with the complete set. However, if this is still taking too much time or causing your computer to freeze it will be OK to submit experiments using a sample size that is feasible for your setting.\n",
    "\n",
    "Grading of the homework will not be affected from this type of variations in the design of your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1: Understanding the data\n",
    "- Load MNIST Fashion training and testing datasets with reduced size (n6000 for training and n1000 for testing)\n",
    "https://drive.google.com/drive/folders/1ytbYCba9LUU_8L2V8Bks7pIfu4x1sXQy\n",
    "\n",
    "Q1.1: What is the number of features in this dataset:   ___\n",
    "\n",
    "Q1.2: What is the number of samples in this dataset:   ___\n",
    "\n",
    "Q1.3: What is the dimensionality of each data sample: ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain=pd.read_csv(\"Data/fashion-mnist_train_n6000.csv\")\n",
    "dftrain.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 785 features in the training dataset.   \n",
    "There are 6000 samples in the training dataset.   \n",
    "Prior to reshaping, each sample is 1x785. After reshaping, each sample is 28x28 pixels (28^2 = 784) + 1 for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=pd.read_csv(\"Data/fashion-mnist_test_n1000.csv\")\n",
    "dftest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 785 features in the test dataset.   \n",
    "There are 1000 samples in the test dataset.   \n",
    "Prior to reshaping, each sample is 1x785. After reshaping, each sample is 28x28 pixels (28^2 = 784) + 1 for for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \\\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "class_names = np.array(class_names) # Need to cast class_names to an np array for S2\n",
    "\n",
    "X=dftrain.iloc[:,1:].values\n",
    "y=dftrain.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2: Viewing the data\n",
    "- Select one random example from each category from the training set. Convert the feature vector for the selected example to a 2D image. Display the image with the name of the category\n",
    "\n",
    "Q2.1: Show the example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "listSel = [] # create emply list to hold selected images\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    temp = np.where(y == i)[0] # Filter for one category of clothes\n",
    "    # randomly select one example for that category:\n",
    "    listSel.append(temp[np.random.choice(len(temp), size = 1, replace = False)]) \n",
    "\n",
    "npListSel = np.array(listSel)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "    \n",
    "for i in range(len(class_names)):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #plt.grid(False)\n",
    "    plt.imshow(X[npListSel[i]].reshape(28,28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y[npListSel[i]]])\n",
    "plt.tight_layout    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3: Exploring the dataset\n",
    "- Select all images in category \"Dress\" in the training set. Create and display a pixel-wise \"average image\" for this category.\n",
    "- Create and display a pixel-wise \"standard deviation image\" for this category.\n",
    "- Repeat the items above for the the category \"Dress\" in the testing set. Compare the average and standard deviation images.\n",
    "- Repeat the items above for a different category you select.\n",
    "\n",
    "Q3.1: Plot the 2D mean and std images for dresses in training and testing sets\n",
    "\n",
    "Q3.2: Plot the 2D mean and std images for the category you selected in training and testing sets\n",
    "\n",
    "Q3.3: Comment on differences between the mean and std images from training and testing datasets. What do you notice, and what might it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMean(df, lbl):\n",
    "    tmp_df = df.loc[df['label'] == lbl] # filter df to include only selected class of images\n",
    "    tmp_df = np.array(tmp_df.mean()) # calculate mean and return to an np array\n",
    "    tmp_df = np.delete(tmp_df, 0) # remove the label column because it causes issues with reshaping\n",
    "    tmp_df = np.rint(tmp_df) # round calculated values to nearest int\n",
    "    tmp_df = tmp_df.astype(int) # cast calculated values to int for visualization\n",
    "    return tmp_df\n",
    "    \n",
    "def calcStdv(df, lbl):\n",
    "    tmp_df = df.loc[df['label'] == lbl] # filter df to include only selected class of images\n",
    "    tmp_df = np.array(tmp_df.std()) # calculate stdv and return to an np array\n",
    "    tmp_df = np.delete(tmp_df, 0) # remove the label column because it causes issues with reshaping\n",
    "    tmp_df = np.rint(tmp_df) # round calculated values to nearest int\n",
    "    tmp_df = tmp_df.astype(int) # cast calculated values to int for visualization\n",
    "    return tmp_df\n",
    "    \n",
    "def vizIndvImg(df):\n",
    "    tmp_df = df.reshape(28,28) # reshape array into 28 x 28 matrix to be vizualized\n",
    "    plt.imshow(tmp_df, cmap=plt.cm.binary)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of training df dresses:\n",
    "vizIndvImg(calcMean(dftrain, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of test df dresses\n",
    "vizIndvImg(calcMean(dftest, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean calculated for the training set is more 'smooth' than the mean of the test dataset. In the vizualization for the test dresses, the dresses with sleaves contribute more to the average dress than they do in the training data. This may indicate that those types of dresses are less represented in the training data when compared to the total number of dresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of training df dresses\n",
    "vizIndvImg(calcStdv(dftrain, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of test df dresses\n",
    "vizIndvImg(calcStdv(dftest, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations made about the average dress are backed up by the visualizations of the standard deviation of dresses from the training and test sets. There is more deviation in the test data than there is in the training data. This may indicate that a model built on these data would be very good at predicting a sleaveless and shapely dress, but may have diminished predictive power on dresses that are wider and have sleaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of training df sneakers:\n",
    "vizIndvImg(calcMean(dftrain, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of test df sneakers\n",
    "vizIndvImg(calcMean(dftest, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard deviation of training df sneakers\n",
    "vizIndvImg(calcStdv(dftrain, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of test df sneakers\n",
    "vizIndvImg(calcStdv(dftest, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4: Image distances\n",
    "- In the training set, find the dress image that is most dissimilar to the average dress image. Show it as a 2D image\n",
    "- In the training set, find the dress image most similar to mean image. Show it as a 2D image\n",
    "\n",
    "Hint: You can use the \"euclidian distance\" as your similarity metric. Given that an image i in category dress is represented with a flattened feature vector v_i , and the mean image for category dress with the feature vector v_m, the distance between these two images can be calculated using the vector norm of their differences ( | v_i - v_m | ) \n",
    "\n",
    "Q4.1: What is the index of most dissimilar dress image:   ___\n",
    "\n",
    "Q4.2: What is the index of most average looking dress image:   ___\n",
    "\n",
    "Q4.3: Plot the most dissimilar dress image in 2D:   ___\n",
    "\n",
    "Q4.4: Plot the most similar dress image in 2D:   ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance func adapted from: https://dataaspirant.com/five-most-popular-similarity-measures-implementation-in-python/\n",
    "\n",
    "def euclidean_distance(x,y):\n",
    "     return sqrt(sum(pow((x-y),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x216e53a08b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanDress = calcMean(dftrain, 3)\n",
    "\n",
    "dresses = np.where(y == 3)[0]\n",
    "\n",
    "dstVctrs = [] # initialize place holder for created Euclidean Distance vectors\n",
    "\n",
    "for i in range(len(dresses)): # Iterate through all dresses in training data\n",
    "    curDress = X[dresses[i]] # get array for current image, to compare to avg dress\n",
    "    curDressED = []\n",
    "    \n",
    "    for j in range(len(meanDress)): # iterate through each pixel\n",
    "        # calculate Euclidean Distance between avg dress and current dress\n",
    "        curDressED.append(abs(curDress[j] - meanDress[j])) # Add ED calculation to current dress result vector\n",
    "    \n",
    "    dstVctrs.append(curDressED) # append ED array for each image to a result list\n",
    "\n",
    "np_dstVctrs = np.array(dstVctrs) # cast output list to an np array\n",
    "\n",
    "\n",
    "edImg = np_dstVctrs[1]\n",
    "edImg = edImg.reshape(28,28)\n",
    "\n",
    "plt.imshow(edImg, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5: Image distances, part 2\n",
    "- Repeat questions S3 and S4 after binarizing the images first\n",
    "\n",
    "Q5.1: What is the index of most dissimilar dress image:   ___\n",
    "\n",
    "Q5.2: What is the index of most similar dress image:   ___\n",
    "\n",
    "Q5.3: Did the answer change after binarization? How do you interprete this finding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6: Binary classification between dresses and sandals\n",
    "- Select images from these two categories (dresses and sandals) in the training dataset\n",
    "- Split them into two sets (Set1, Set2) with 70% to 30% random split\n",
    "- Replace category labels as 0 (dress) and 1 (sandal)\n",
    "- Use Set1 to train a linear SVM classifier with default parameters and predict the class labels for Set2 \n",
    "- Use Set2 to train a linear SVM classifier with default parameters and predict the class labels for Set1 \n",
    "\n",
    "Q6.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q6.2: What is the prediction accuracy using the model trained on Set2:   ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7: Binary classification between dresses and sandals, part 2\n",
    "- Select images from these two categories (dresses and sandals) in the training dataset\n",
    "- Split them into two sets (Set1, Set2) with 20% to 80% random split\n",
    "- Select images from these two categories in the testing dataset\n",
    "- Replace category labels as 0 (dress) and 1 (sandal)\n",
    "- Use Set1 to train a linear SVM classifier with default parameters and predict the class labels for testing images \n",
    "- Use Set2 to train a linear SVM classifier with default parameters and predict the class labels for testing images\n",
    "\n",
    "Q7.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q7.2: What is the prediction accuracy using the model trained on Set2:   ___\n",
    "\n",
    "Q7.3: Comment on the differences in the accuracy of the two models. If there is a difference, why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S8: k-NN Error Analysis\n",
    "- In training and testing datasets select the images with labels: Dress, Coat, Sandal, Shirt or Sneaker\n",
    "- Train a k-NN classifier using 4 to 40 nearest neighbors with a step size of 4\n",
    "- Calculate and plot overall testing accuracy for each experiment\n",
    "\n",
    "Q8.1: For k=4 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q8.2: For k=20 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q8.3: What is the label pair that was confused most often (i.e. class A is labeled as B, and vice versa):   ___\n",
    "\n",
    "Q8.4: Visualize 5 mislabeled samples with their actual and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9: Feature extraction\n",
    "- We describe each image by using a reduced set of features (compared to n=784 initial features for each pixel value) as follows:\n",
    "  \n",
    "  1. Binarize the image (background=0, foreground=1)\n",
    "  2. For each row i, find m_i, the index of the first non-zero pixel (m_i will be a value from 0 to 28 - if all pixels in a row are zero then m_i=28)\n",
    "  \n",
    "  Example image:\n",
    "       0 0 0 0 1 1 1 ...\n",
    "       0 0 1 1 1 0 0 ...\n",
    "       0 0 0 0 0 1 0 ...\n",
    "       ...\n",
    "  Extracted features:     [4, 2, 5, ...]\n",
    "  \n",
    "  This strategy gives a feature vector with n=28 features (for each row)\n",
    "  \n",
    "  Repeat classification experiments in Q6 using this reduced feature set.\n",
    "\n",
    "Q9.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q9.2: What is the prediction accuracy using the model trained on Set2:   ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Repeat S9 by extracting 28x4 features this time by applying the same rule in four different directions and concatenating them (left->right, right->left, top->bottom, bottom->top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
